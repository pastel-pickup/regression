{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 998,
   "id": "e2a92259",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "id": "44f93c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "id": "2ebe91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'https://www.indeed.com/jobs?q={}&l={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "id": "b66ff050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(position, location):\n",
    "    \"\"\" Generate a url from position and location\"\"\"\n",
    "    template = 'https://www.indeed.com/jobs?q={}&l={}'\n",
    "    url = template.format(position, location)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "e4199e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_url('Machine Learning Engineer', 'new york ny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cf25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f26a00da",
   "metadata": {},
   "source": [
    "# Extract raw html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "2201b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "eee28238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09a8bca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "6fc089fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "81377ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = soup.find_all('td', 'resultContent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "329ad44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15ecac",
   "metadata": {},
   "source": [
    "# Prototype the model with a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "id": "a8afb773",
   "metadata": {},
   "outputs": [],
   "source": [
    "card = cards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "504327d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_tag = card.div.h2.span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "ec5fc82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Engineer\n"
     ]
    }
   ],
   "source": [
    "job_title = soup.find(text='Machine Learning Engineer')\n",
    "print(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5850d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# job_title = title_tag.get('title') # JOB TITLE (1)\n",
    "# print(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "be430448",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = card.div.span.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b1cc99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = soup.find('a', {'data-tn-element':'companyName'}).text.strip() #COMPANY NAME (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "db9aa8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HarperCollins Publishers\n"
     ]
    }
   ],
   "source": [
    "print(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7f2e8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_location = soup.find('div', 'companyLocation').text.strip() #COMPANY LOCATION (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "71c2125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York, NY•Remote\n"
     ]
    }
   ],
   "source": [
    "print(job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "eb0d67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_rating = card.div.span.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ea485926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9\n"
     ]
    }
   ],
   "source": [
    "company_rating = soup.find('a', {'data-tn-variant':'cmplinktst2'}).text.strip() #COMPANY RATING (4)\n",
    "print(company_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "baecd74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-23\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d') # TODAY's DATE (5)\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7fba9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary = card.div.div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "218dbfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated $96.1K – $122K a year\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    salary = soup.find('div', {'class':'heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly'}).text.strip() # SALARY (6)\n",
    "except AttributeError:\n",
    "    salary = ''\n",
    "\n",
    "print(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6cbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "087c5e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if soup.find('span', {'class':'remote-bullet'}):\n",
    "    remote = True\n",
    "else:\n",
    "    remote = False\n",
    "#REMOTE (7)\n",
    "print(remote)\n",
    "\n",
    "# remote = True\n",
    "# print(remote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c8b48509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posted30+ days ago\n"
     ]
    }
   ],
   "source": [
    "age = soup.find('span', 'date').text.strip() #POST AGE (8)\n",
    "print(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "db7ec0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# urgent = soup.find('div', {'class':'urgentlyHiring'}).text #URGENT (9)\n",
    "# print(urgent)\n",
    "try:\n",
    "    urgent = soup.find('div', {'class':'urgentlyHiring'}).text # EASY APPLY\n",
    "except AttributeError:\n",
    "    urgent = ''\n",
    "\n",
    "print(urgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "46edeeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easily apply\n"
     ]
    }
   ],
   "source": [
    "# if soup.find('span', {'class': 'ialbl iaTextBlack'}): #EASY APPLY\n",
    "#     easy_apply = True\n",
    "# else:\n",
    "#     easy_apply = False\n",
    "# print(easy_apply)\n",
    "# if soup.find('tr', {'class': 'jobCardShelf'}):\n",
    "#     easy_apply = True\n",
    "# else:\n",
    "#     easy_apply = False\n",
    "\n",
    "# print(easy_apply)\n",
    "\n",
    "try:\n",
    "    easy_apply = soup.find('tr', {'class': 'jobCardShelf'}).text # EASY APPLY\n",
    "except AttributeError:\n",
    "    easy_apply = ''\n",
    "\n",
    "print(easy_apply)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209436e",
   "metadata": {},
   "source": [
    "# Generalize the model with a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "id": "592a4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(card):\n",
    "    \"\"\"Extract job data from a single record\"\"\"\n",
    "    job_title = soup.find(text='Machine Learning Engineer') # JOB TITLE\n",
    "    try:\n",
    "        company = soup.find('a', {'data-tn-element':'companyName'}).text.strip() #COMPANY NAME\n",
    "    except AttributeError:\n",
    "        company = ''\n",
    "    job_location = soup.find('div', 'companyLocation').text.strip() #COMPANY LOCATION\n",
    "    try:\n",
    "        company_rating = soup.find('a', {'data-tn-variant':'cmplinktst2'}).text.strip() #COMPANY RATING\n",
    "    except AttributeError:\n",
    "        company_rating = ''\n",
    "    today = datetime.today().strftime('%Y-%m-%d') # TODAY's DATE\n",
    "    age = soup.find('span', 'date').text.strip() #POST AGE\n",
    "    if soup.find('span', {'class':'remote-bullet'}): #REMOTE\n",
    "        remote = True\n",
    "    else:\n",
    "        remote = False\n",
    "    try:\n",
    "        salary = soup.find('div', {'class':'heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly'}).text.strip() # SALARY\n",
    "    except AttributeError:\n",
    "        salary = ''\n",
    "    try:\n",
    "        urgent = soup.find('div', {'class':'urgentlyHiring'}).text.strip() #URGENT\n",
    "    except AttributeError:\n",
    "        urgent = 'Not Urgent'\n",
    "    try:\n",
    "        easy_apply = soup.find('tr', {'class': 'jobCardShelf'}).text # EASY APPLY\n",
    "    except AttributeError:\n",
    "        easy_apply = '' \n",
    "    \n",
    "    record = (job_title, company, job_location, company_rating, salary, remote, urgent, easy_apply, age, today)\n",
    "    return record\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "id": "3fbd6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for card in cards:\n",
    "    record = get_record(card)\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "id": "9243f30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Machine Learning Engineer',\n",
       " 'Capital One',\n",
       " 'New York, NY 10012 (SoHo area)+126 locations',\n",
       " '3.9',\n",
       " 'From $75,000 a year',\n",
       " True,\n",
       " 'Not Urgent',\n",
       " '',\n",
       " 'Posted2 days ago',\n",
       " '2022-01-25')"
      ]
     },
     "execution_count": 1011,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d74b5",
   "metadata": {},
   "source": [
    "# Getting the next page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "id": "e3915ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try: \n",
    "        url = 'https://www.indeed.com' + soup.find('a', {'aria-label':'Next'}).get('href')\n",
    "    except AttributeError:\n",
    "        break\n",
    "        \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    cards = soup.find_all('td', 'resultContent')\n",
    "    \n",
    "    for card in cards:\n",
    "        record = get_record(card)\n",
    "        records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "id": "7949e250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "id": "1bf2788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "id": "4dfd4246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ml_17.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579a096",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76b8301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# from datetime import datetime\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# def get_url(position, location):\n",
    "#     \"\"\" Generate a url from position and location\"\"\"\n",
    "#     template = 'https://www.indeed.com/jobs?q={}&l={}'\n",
    "#     url = template.format(position, location)\n",
    "#     return url\n",
    "\n",
    "# def get_record(card):\n",
    "#     \"\"\"Extract job data from a single record\"\"\"\n",
    "#     job_title = title_tag.get('title') # JOB TITLE\n",
    "#     company = soup.find('a', {'data-tn-element':'companyName'}).text.strip() #COMPANY NAME\n",
    "#     job_location = soup.find('div', 'companyLocation').text.strip() #COMPANY LOCATION\n",
    "#     company_rating = soup.find('a', {'data-tn-variant':'cmplinktst2'}).text.strip() #COMPANY RATING\n",
    "#     today = datetime.today().strftime('%Y-%m-%d') # TODAY's DATE\n",
    "#     age = soup.find('span', 'date').text.strip() #POST AGE\n",
    "#     remote = soup.find('span', {'class':'remote-bullet'}) #REMOTE\n",
    "#     remote = True\n",
    "#     try:\n",
    "#         salary = soup.find('div', {'class':'heading6 tapItem-gutter metadataContainer noJEMChips salaryOnly'}).text.strip() # SALARY\n",
    "#     except AttributeError:\n",
    "#         salary = ''\n",
    "    \n",
    "#     record = (job_title, company, job_location, company_rating, salary, remote, age, today)\n",
    "#     return record\n",
    "    \n",
    "# def main(position, location):\n",
    "#     \"\"\"Run the main program\"\"\"\n",
    "#     records = []\n",
    "#     url = get_url(position, location)\n",
    "    \n",
    "#     # extract the job data\n",
    "#     while True:\n",
    "#         response = requests.get(url)\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#         cards = soup.find_all('td', 'resultContent')\n",
    "    \n",
    "#         for card in cards:\n",
    "#             record = get_record(card)\n",
    "#             records.append(record)\n",
    "            \n",
    "#         try: \n",
    "#             url = 'https://www.indeed.com' + soup.find('a', {'aria-label':'Next'}).get('href')\n",
    "#         except AttributeError:\n",
    "#             break\n",
    "            \n",
    "#     # save the job data\n",
    "#     with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(['JobTitle', 'Company', 'Location', 'Rating', 'Salary', 'Remote', 'PostDate', 'ExtractDate'])\n",
    "#         writer.writerows(records)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0be9daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run the program\n",
    "# main('data scientist', 'new york, ny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b223e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
